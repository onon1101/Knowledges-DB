
Flops 跟機器的算力有關，但作者說Flops 其實根本就不太需要關心
MEM的速度是：200G Bytes / s = ( 25G-FP64 / s ) * 8 Bytes
> ps: FP64 = 8Bytes


CPU 能處理的速度是：2000G TFLOPs FP64

[[Required Compute Intensity]] = $\frac{FLOPs}{Data Rate}$ = 80
意思是說：載入一次資料後，需要對資料做80次的計算才能滿足效能，否則CPU會空閒下來。

![[Pasted image 20230911162906.png]]
大部分的計算強度(Required Compute Inntensity) 都一樣，不過隨著處理能力大於MEM的傳送能力，計算強度就會升高，代表我們必須增加算法，以滿足一筆資料能做好次的運算

---
不過在實際中，更關心的是延遲，而不是計算強度。
### DAXPY: $\alpha$X+Y=Z
> 在CPU裡面其實可以用[[FMA]]來完成一個指令，完成多個這類運算

在GPU Pipeline裡面，由於X要先與$\alpha$相乘，然後在與Y相加。所以先加載Ｘ，不過記憶體可以多次要求。

> 以下是Pipeline，而在程序裡面，如果用原本的順序，會使CPU有大部分時間都在等待，因此編譯器會移動大量的代碼去優化CPU在等待資料傳送的時間。
>
> 而現在記憶體延遲比計算延遲還要高，不過這是因為...
![[Pasted image 20230911163920.png]]

- 光的傳播速度 = 300,000,000 m
- 電腦的頻率     = 3,000,000,000 Hz
- 電的速度         = 60,000,000 m

所以光 1 clock = 100mm ( 0.1cm )
因為頻率真的太高了，因此走不遠

電 1 clock = 20 mm

> 在下途中，電從左邊到右邊就需要花費5~7 個週期，不過這只是一個示意。實際上並不會這樣。
![[Pasted image 20230911165236.png]]

實際上是晶片是從一個電晶體傳送到另外一個電晶體，那麼晶片就會自動調整頻率使得可以上彌補電流的速度，不過實際是為了跟上CPU的Pipeline。

在Intel Xeon 8280 的CPU上面
mem bandwidth: 131 GB /s 
記憶體延遲是:      89ns /s

因此在延遲的時間中可以傳送：11,659 Bytes in 89 ns
但是我們在$\alpha$X + Y = Z 的時候用的是 32Bytes，所以實際的傳輸效率是0.14%
有99.86%的時間都用浪費在等待記憶體延遲了

![[Pasted image 20230911203700.png]]

因此就算我有很高的處理時間，但是用在等待的延遲時間實在太多了，改善計算時間並沒有辦法大幅改善整體時間。

上面的問題稱為[[latency bound]]，他發生的次數非常的多，是內存限制的一個子集

不過在GPU裡面，如果要讓記憶體滿載的話需要$\frac{11,659}{16}=729$次運算在一個時間段，也就是需要使用到並行的技術

在編譯器裡面有一種優化叫[[Loop Unrolling]]（循環展開），可以由編譯器或者開發人員完成（back to back all at once)

可以用一個線程使用Loop Unrolling 後，發送729個迭代請求就沒問題

假設一個線程只能發出一個請求那麼需要729個線程，此時問題就變成如果能容納更多的線程，那麼運算的效率就會更高。像是A100可以容納5倍的線程數量，但CPU只能容納896的線程數使得記憶體頻寬以1.2倍的速度傳輸。

![[Pasted image 20230911205714.png]]

因此 GPU的設計重點在於 如何增加線程的容納數量
而CPU在於 如何減少延遲
這是他們根本的區別

---
以下是我還不太了解的地方
在GPU裡面 寄存器也被視作一種Cache，每個大量的線程中都會使用寄存器，因為每個緩存的延遲和速度都不一樣，所以如果需要足夠大的記憶體空間來完成FLOPs請求

在A100中寄存器達到了27MB的容量，而寄存器的出現使得緩存的速度可以不同，不過大量的數據也是GPU的基礎。

下面是寬帶與延遲所造成的計算強度圖，這邊也解釋了為什麼不使用PCIE，因為他載入一次資料就要超多的運算，

![[Pasted image 20230911220345.png]]

### 問題
不過我的問題在於說，HBM的寬帶只有那麼一點但他上面的寬帶都很高，這樣子不會使上面一直等待HBM的回應嗎，因為上面的傳送速度比下面快

---
### 使記憶體忙碌

因為計算強度很高，所以我們必須讓每一個核心的是工作的狀態，你可以看到線程數是逐漸遞減的，這使得如果有處理單元的線程壓力比較小的時候，就能自動分配給那一個處理單元

不過這邊也提到了，如果某一個記憶體系統的線程要求很高的話，就是會變成瓶頸
但我不太知道為什麼
![[Pasted image 20230911221118.png]]

---
SM使一個基本的處理單元，每組SM裡面都會有[[warp]]，是由32個線程為一組，為一個GPU調度的基本單位，一個SM包含64個[[warp]]，最多能同時並行4組[[warp]]

不過在一個single clock cycle裡面，可以做到很快的從一個warp切換到下一個warp，且不會有上下文切換的代價。通常運行的線程會超過128個，因為要超額配量（oversubscribe）
![[Pasted image 20230912072414.png]]

---
異步對於GPU來說同樣重要，因為對於矩陣算法而言